{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "distributed_training2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM25gAyuSybpCokcpB95WAK"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "m30_MQxANHxj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c37f6591-fca7-44d9-8d24-0d611b6562ec"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rk9oxmy0NRlB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "outputId": "5c0448e7-1b47-4d43-d794-fb0e44527a2e"
      },
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "train_images = train_images[..., None]\n",
        "test_images = test_images[..., None]\n",
        "\n",
        "train_images = train_images / np.float32(255)\n",
        "test_images = test_images / np.float32(255)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6L_iZ55INsJJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f46392c1-6379-42e3-a1c5-59d06b52a42f"
      },
      "source": [
        "strategy = tf.distribute.MirroredStrategy()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1ATWBZIN3J4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6355beff-317c-41dd-e1bd-74b51e35fcf0"
      },
      "source": [
        "print(f\"Number of devices: {strategy.num_replicas_in_sync}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of devices: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZB8rvR9N7Il",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = len(train_images)\n",
        "\n",
        "BATCH_SIZE_PER_REPLICA = 64\n",
        "GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
        "\n",
        "EPOCHS = 10"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkuU2fRyOItS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(BUFFER_SIZE).batch(GLOBAL_BATCH_SIZE)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(GLOBAL_BATCH_SIZE)\n",
        "\n",
        "train_dist_dataset = strategy.experimental_distribute_dataset(train_dataset)\n",
        "test_dist_dataset = strategy.experimental_distribute_dataset(test_dataset)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42NjCzNzOsjy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model():\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, 3, activation=\"relu\"),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Conv2D(64, 3, activation=\"relu\"),\n",
        "    tf.keras.layers.MaxPool2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(10)                             \n",
        "  ])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aG7QXi7PH0H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = \"./training/checkpoints\"\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-3Hf829PQy1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with strategy.scope():\n",
        "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True,\n",
        "      reduction=tf.keras.losses.Reduction.NONE\n",
        "  )\n",
        "  def compute_loss(labels, predictions):\n",
        "    per_example_loss = loss_object(labels, predictions)\n",
        "    return tf.nn.compute_average_loss(per_example_loss, global_batch_size=GLOBAL_BATCH_SIZE)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLS4gVr8P-7I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with strategy.scope():\n",
        "  test_loss = tf.keras.metrics.Mean(name=\"test_loss\")\n",
        "\n",
        "  train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=\"train_accuracy\")\n",
        "  test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=\"test_accuracy\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xV2HK0LiQP5O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with strategy.scope():\n",
        "  model = create_model()\n",
        "\n",
        "  optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "  checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdE4c9_WQbEK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_step(inputs):\n",
        "  images, labels = inputs\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model(images, training=True)\n",
        "    loss = compute_loss(labels, predictions)\n",
        "\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "  train_accuracy.update_state(labels, predictions)\n",
        "  return loss\n",
        "\n",
        "def test_step(inputs):\n",
        "  images, labels = inputs\n",
        "\n",
        "  predictions = model(images, training=False)\n",
        "  t_loss = loss_object(labels, predictions)\n",
        "\n",
        "  test_loss.update_state(t_loss)\n",
        "  test_accuracy.update_state(labels, predictions)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qvv56zjJRJUm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "8010dc2e-f13d-4b96-eb94-101b08e6d0c6"
      },
      "source": [
        "@tf.function\n",
        "def distributed_train_step(dataset_inputs):\n",
        "  per_replica_losses = strategy.run(train_step, args=(dataset_inputs,))\n",
        "  return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n",
        "\n",
        "@tf.function\n",
        "def distributed_test_step(dataset_inputs):\n",
        "  return strategy.run(test_step, args=(dataset_inputs,))\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  total_loss = 0.0\n",
        "  num_batches = 0\n",
        "  for x in train_dist_dataset:\n",
        "    total_loss += distributed_train_step(x)\n",
        "    num_batches += 1\n",
        "  train_loss = total_loss / num_batches\n",
        "\n",
        "  for x in test_dist_dataset:\n",
        "    distributed_test_step(x)\n",
        "  \n",
        "  if epoch % 2 == 0:\n",
        "    checkpoint.save(checkpoint_prefix)\n",
        "  \n",
        "  print(f\"Epoch {epoch+1}, Loss: {train_loss}, Accuracy: {train_accuracy.result()*100}, Test Loss: {test_loss.result()}, Test Accuracy: {test_accuracy.result()*100}\")\n",
        "\n",
        "  test_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  test_accuracy.reset_states()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "Epoch 1, Loss: 0.5160505771636963, Accuracy: 81.47333526611328, Test Loss: 0.40085989236831665, Test Accuracy: 85.12999725341797\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "Epoch 2, Loss: 0.3423827886581421, Accuracy: 87.58333587646484, Test Loss: 0.33408820629119873, Test Accuracy: 88.33000183105469\n",
            "Epoch 3, Loss: 0.2964332103729248, Accuracy: 89.33833312988281, Test Loss: 0.31934601068496704, Test Accuracy: 88.68000030517578\n",
            "Epoch 4, Loss: 0.2656244933605194, Accuracy: 90.23500061035156, Test Loss: 0.2874595820903778, Test Accuracy: 89.55000305175781\n",
            "Epoch 5, Loss: 0.24176886677742004, Accuracy: 91.13500213623047, Test Loss: 0.2816489636898041, Test Accuracy: 89.9800033569336\n",
            "Epoch 6, Loss: 0.21887557208538055, Accuracy: 91.8699951171875, Test Loss: 0.26756930351257324, Test Accuracy: 90.25\n",
            "Epoch 7, Loss: 0.20292553305625916, Accuracy: 92.48832702636719, Test Loss: 0.28907597064971924, Test Accuracy: 89.7800064086914\n",
            "Epoch 8, Loss: 0.18682372570037842, Accuracy: 93.09832763671875, Test Loss: 0.27205345034599304, Test Accuracy: 90.41999816894531\n",
            "Epoch 9, Loss: 0.169932559132576, Accuracy: 93.70500183105469, Test Loss: 0.2573537230491638, Test Accuracy: 90.97000122070312\n",
            "Epoch 10, Loss: 0.1558409035205841, Accuracy: 94.22167205810547, Test Loss: 0.2677972912788391, Test Accuracy: 91.00999450683594\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5cCYq81SmT0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eval_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=\"eval_accuracy\")\n",
        "\n",
        "new_model = create_model()\n",
        "new_optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(GLOBAL_BATCH_SIZE)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBj9da2zUSfY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def eval_step(images, labels):\n",
        "  predictions = new_model(images, training=False)\n",
        "  eval_accuracy(labels, predictions)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvlBcZnGUcJP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5ad282c6-8183-49b7-8b7c-041fe3f7fb9d"
      },
      "source": [
        "checkpoint = tf.train.Checkpoint(optimizer=new_optimizer, model=new_model)\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "for images, labels, in test_dataset:\n",
        "  eval_step(images, labels)\n",
        "\n",
        "print(f\"Accuracy after restoring the saved model without strategy: {eval_accuracy.result()*100}\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy after restoring the saved model without strategy: 90.97000122070312\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSXvok-qU2CP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "098cd53c-bc36-4650-ee7f-00b3b9d85737"
      },
      "source": [
        "for _ in range(EPOCHS):\n",
        "  total_loss = 0.0\n",
        "  num_batches = 0\n",
        "  train_iter = iter(train_dist_dataset)\n",
        "\n",
        "  for _ in range(10):\n",
        "    total_loss += distributed_train_step(next(train_iter))\n",
        "    num_batches += 1\n",
        "  average_train_loss = total_loss / num_batches\n",
        "\n",
        "  print(f\"Epoch {epoch+1}, Loss: {train_loss}, Accuracy: {train_accuracy.result()*100}\")\n",
        "  train_accuracy.reset_states()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 10, Loss: 0.1558409035205841, Accuracy: 96.09375\n",
            "Epoch 10, Loss: 0.1558409035205841, Accuracy: 95.15625\n",
            "Epoch 10, Loss: 0.1558409035205841, Accuracy: 93.59375\n",
            "Epoch 10, Loss: 0.1558409035205841, Accuracy: 96.25\n",
            "Epoch 10, Loss: 0.1558409035205841, Accuracy: 95.15625\n",
            "Epoch 10, Loss: 0.1558409035205841, Accuracy: 93.75\n",
            "Epoch 10, Loss: 0.1558409035205841, Accuracy: 94.21875\n",
            "Epoch 10, Loss: 0.1558409035205841, Accuracy: 94.21875\n",
            "Epoch 10, Loss: 0.1558409035205841, Accuracy: 95.46875\n",
            "Epoch 10, Loss: 0.1558409035205841, Accuracy: 95.625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuhviaBuy1qA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "5d22da53-813e-4721-c52b-0bd466dbbe74"
      },
      "source": [
        "@tf.function\n",
        "def distributed_train_epoch(dataset):\n",
        "  total_loss = 0.0\n",
        "  num_batches = 0\n",
        "  for x in dataset:\n",
        "    per_replica_losses = strategy.run(train_step, args=(x,))\n",
        "    total_loss += strategy.reduce(\n",
        "        tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None\n",
        "    )\n",
        "    num_batches += 1\n",
        "  return total_loss / tf.cast(num_batches, dtype=tf.float32)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  train_loss = distributed_train_epoch(train_dist_dataset)\n",
        "\n",
        "  print(f\"Epoch {epoch+1}, Loss: {train_loss}, Accuracy: {train_accuracy.result()*100}\")\n",
        "  train_accuracy.reset_states()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 0.14259059727191925, Accuracy: 94.74666595458984\n",
            "Epoch 2, Loss: 0.13192428648471832, Accuracy: 95.11000061035156\n",
            "Epoch 3, Loss: 0.11616019904613495, Accuracy: 95.67833709716797\n",
            "Epoch 4, Loss: 0.10837100446224213, Accuracy: 95.99833679199219\n",
            "Epoch 5, Loss: 0.10041636973619461, Accuracy: 96.27833557128906\n",
            "Epoch 6, Loss: 0.0895528495311737, Accuracy: 96.69499969482422\n",
            "Epoch 7, Loss: 0.08159716427326202, Accuracy: 97.0\n",
            "Epoch 8, Loss: 0.07712753862142563, Accuracy: 97.1433334350586\n",
            "Epoch 9, Loss: 0.07018831372261047, Accuracy: 97.40666961669922\n",
            "Epoch 10, Loss: 0.06551890075206757, Accuracy: 97.51333618164062\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}